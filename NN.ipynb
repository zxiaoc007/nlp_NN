{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Activation, merge, Input, Lambda, Reshape\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM, GRU, TimeDistributed, Bidirectional, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/xiaochenzhang/Desktop/PersonalProjects/nlp_NN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfidf_folder.tfidf import get_instance_tfidf_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "* take first 10000 training data\n",
    "* take first 4000 testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/4w_trainset.csv', encoding='GB18030')\n",
    "test_data = pd.read_csv('data/4k_testset.csv', encoding='GB18030')\n",
    "train_data = train_data[:10000]\n",
    "test_data = test_data[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>工单编号</th>\n",
       "      <th>行业分类1级</th>\n",
       "      <th>行业分类2级</th>\n",
       "      <th>行业分类3级</th>\n",
       "      <th>行业分类4级</th>\n",
       "      <th>诉求内容</th>\n",
       "      <th>原处置单位</th>\n",
       "      <th>处置单位</th>\n",
       "      <th>单位类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>20180102124706</td>\n",
       "      <td>司法行政</td>\n",
       "      <td>其他</td>\n",
       "      <td>其他</td>\n",
       "      <td>其他</td>\n",
       "      <td>市民来电咨询: 万绿园政府服务中心五楼的消防窗口的电话。</td>\n",
       "      <td>市公安局消防支队</td>\n",
       "      <td>公安局消防支队</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>20180101115513</td>\n",
       "      <td>其他</td>\n",
       "      <td>其他</td>\n",
       "      <td>其他</td>\n",
       "      <td>其他</td>\n",
       "      <td>市民来电咨询：驾驶证过期换证的问题</td>\n",
       "      <td>市公安局交通警察支队</td>\n",
       "      <td>公安局交通警察支队</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>20180117311266</td>\n",
       "      <td>公安（治安、交通）</td>\n",
       "      <td>其他</td>\n",
       "      <td>其他</td>\n",
       "      <td>其他</td>\n",
       "      <td>市民微信反映: 琼山区下坎西球场对面有人在聚众赌博（旁边有个停车场），请市公安局核实处理。（...</td>\n",
       "      <td>市公安局</td>\n",
       "      <td>公安局</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>20180109210991</td>\n",
       "      <td>“12345”热线</td>\n",
       "      <td>传真信息</td>\n",
       "      <td>信息咨询</td>\n",
       "      <td>信息咨询</td>\n",
       "      <td>市民来电咨询:咨询驾管所电话。</td>\n",
       "      <td>市公安局交通警察支队</td>\n",
       "      <td>公安局交通警察支队</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>20180101118432</td>\n",
       "      <td>城乡建设</td>\n",
       "      <td>道路维护</td>\n",
       "      <td>路面养护</td>\n",
       "      <td>路面污染</td>\n",
       "      <td>市民来电反映:在美兰区灵山镇往文昌方向的琼文大道机场路段每天都有工地车辆洒落泥土在路上，请城...</td>\n",
       "      <td>美兰区城管局</td>\n",
       "      <td>城市管理行政执法局</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID            工单编号     行业分类1级 行业分类2级 行业分类3级 行业分类4级  \\\n",
       "0   6  20180102124706       司法行政     其他     其他     其他   \n",
       "1   7  20180101115513         其他     其他     其他     其他   \n",
       "2  15  20180117311266  公安（治安、交通）     其他     其他     其他   \n",
       "3  17  20180109210991  “12345”热线   传真信息   信息咨询   信息咨询   \n",
       "4  21  20180101118432       城乡建设   道路维护   路面养护   路面污染   \n",
       "\n",
       "                                                诉求内容       原处置单位       处置单位  \\\n",
       "0                       市民来电咨询: 万绿园政府服务中心五楼的消防窗口的电话。    市公安局消防支队    公安局消防支队   \n",
       "1                                  市民来电咨询：驾驶证过期换证的问题  市公安局交通警察支队  公安局交通警察支队   \n",
       "2  市民微信反映: 琼山区下坎西球场对面有人在聚众赌博（旁边有个停车场），请市公安局核实处理。（...        市公安局        公安局   \n",
       "3                                    市民来电咨询:咨询驾管所电话。  市公安局交通警察支队  公安局交通警察支队   \n",
       "4  市民来电反映:在美兰区灵山镇往文昌方向的琼文大道机场路段每天都有工地车辆洒落泥土在路上，请城...      美兰区城管局  城市管理行政执法局   \n",
       "\n",
       "   单位类别  \n",
       "0     3  \n",
       "1     3  \n",
       "2     3  \n",
       "3     3  \n",
       "4     2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\n",
    "    'ID': train_data['ID'],\n",
    "    'Label': train_data[train_data.columns[-1]],\n",
    "    'Feature': train_data['ID'].apply(lambda x: get_instance_tfidf_vector(str(x), False))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[7.345027488669131, 2.1331498953028616, 1.6502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.8212059778186624, 3.14354571...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Label                                            Feature\n",
       "0   6      3  [7.345027488669131, 2.1331498953028616, 1.6502...\n",
       "1   7      3  [0.0, 0.0, 0.0, 2.8212059778186624, 3.14354571..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    'Label': test_data[test_data.columns[-1]],\n",
    "    'Feature': test_data['ID'].apply(lambda x: get_instance_tfidf_vector(str(x), False))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the test dataset\n",
    "* find a lot of all-zero records in test data after tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Nzero'] = test['Feature'].apply(lambda x: np.count_nonzero(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Nzero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Feature  Nzero\n",
       "Label                     \n",
       "0      277      277    277\n",
       "1      605      605    605\n",
       "2      561      561    561\n",
       "3      576      576    576\n",
       "4      304      304    304"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['Nzero'] == 0].groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test2 after filtering all-zero records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test[test['Nzero'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download after-processing train and test dataset to local, save time for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train['Feature'].values.tolist())\n",
    "y_train = train['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test2['Feature'].values.tolist())\n",
    "y_test = test2['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train.npy', x_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('x_test.npy', x_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('x_train.npy')[0:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.load('y_train.npy')[0:num]\n",
    "X_test_true = np.load('x_test.npy')\n",
    "Y_test_true = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = pd.DataFrame(Y_train)[0]\n",
    "# Y_test = pd.DataFrame(Y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 4, 2, 2])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset to training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, X_test, y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)[0]\n",
    "y_val = pd.DataFrame(y_val)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot processing for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot，5 category\n",
    "y_labels = list(y_train.value_counts().index)\n",
    "#y_labels = np.unique(y_train)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_labels)\n",
    "num_labels = len(y_labels)\n",
    "y_train = to_categorical(y_train.map(lambda x: le.transform([x])[0]), num_labels)\n",
    "y_val = to_categorical(y_val.map(lambda x: le.transform([x])[0]), num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41925"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1677./4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从”Train.csv“中取出10000个data，分为Train, Val, Test三份：\n",
      "     Train:  6400 用于训练\n",
      "     Val:  1600 用于训练过程中validation\n",
      "     Test: 2000 训练结束后用于检测\n",
      "\n",
      "\n",
      "从\"Test.csv\"中取出4000个data，tfidf处理后有60%data的全部feature都是0，过滤掉了这部分后剩下40%\n",
      "     True Test:  1677 训练结束后用于检测\n"
     ]
    }
   ],
   "source": [
    "print('从”Train.csv“中取出10000个data，分为Train, Val, Test三份：')\n",
    "print('     Train: ', x_train.shape[0], '用于训练')\n",
    "print('     Val: ', x_val.shape[0], '用于训练过程中validation')\n",
    "print('     Test:', X_test.shape[0], '训练结束后用于检测')\n",
    "print('\\n')\n",
    "print('从\"Test.csv\"中取出4000个data，tfidf处理后有60%data的全部feature都是0，过滤掉了这部分后剩下40%')\n",
    "print('     True Test: ', X_test_true.shape[0], '训练结束后用于检测')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Provided by Prof Liu\n",
    "* have converted to Keras platform\n",
    "* not able to up and run on my local laptop by limited resouce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous\n",
    "model = Sequential()\n",
    "model.add(Embedding(x_train.shape[0], 3000, input_shape=(x_train.shape[1],)))\n",
    "model.add(Convolution1D(128, 5, activation='relu'))\n",
    "model.add(MaxPool1D(5, 5,padding='same'))\n",
    "model.add(Convolution1D(128, 5, activation='relu'))\n",
    "model.add(MaxPool1D(5, 5,padding='same'))\n",
    "model.add(Convolution1D(128, 5, activation='relu'))\n",
    "model.add(MaxPool1D(35, 35,padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=1000,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "# embedded_sequences = embedding_layer(sequence_input)\n",
    "#l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "#l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "#l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "#l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "#l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "#l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "#l_flat = Flatten()(l_pool3)\n",
    "#l_dense = Dense(128, activation='relu')(l_flat)\n",
    "#preds = Dense(len(macronum), activation='softmax')(l_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: MLP, Multilayer Perceptron\n",
    "* reference: https://zhuanlan.zhihu.com/p/29201491\n",
    "* a simple NN model\n",
    "* the only one that can be run on my laptop\n",
    "* have best result as train_acc: 0.9798, val_acc: 0.8138, test_acc: 0.8095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 17s 3ms/step - loss: 1.1760 - acc: 0.5619 - val_loss: 0.7521 - val_acc: 0.7763\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.4052 - acc: 0.8887 - val_loss: 0.6043 - val_acc: 0.8231\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.1903 - acc: 0.9408 - val_loss: 0.6813 - val_acc: 0.8181\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.1333 - acc: 0.9589 - val_loss: 0.7499 - val_acc: 0.8125\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.1047 - acc: 0.9688 - val_loss: 0.7577 - val_acc: 0.8188\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.0861 - acc: 0.9730 - val_loss: 0.7879 - val_acc: 0.8156\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 13s 2ms/step - loss: 0.0826 - acc: 0.9761 - val_loss: 0.8265 - val_acc: 0.8181\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.0714 - acc: 0.9761 - val_loss: 0.8602 - val_acc: 0.8169\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.0717 - acc: 0.9780 - val_loss: 0.8777 - val_acc: 0.8125\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 12s 2ms/step - loss: 0.0707 - acc: 0.9798 - val_loss: 0.9058 - val_acc: 0.8138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a42a8df98>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=500,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test result\n",
    "* one test dataset is from train.csv\n",
    "* one test is from test.csv\n",
    "* two results have large difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict_classes(X_test), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24090638044126417"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict_classes(X_test_true), Y_test_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: CNN model\n",
    "* not able to run on local machine...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 19607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(x_train.shape[0], 3000, input_shape=(x_train.shape[1],)))\n",
    "model.add(Convolution1D(256, 3, padding='same'))\n",
    "model.add(MaxPool1D(3,3,padding='same'))\n",
    "model.add(Convolution1D(128, 3, padding='same'))\n",
    "model.add(MaxPool1D(3,3,padding='same'))\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization()) # (批)规范化层\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: LSTM model\n",
    "* not able to run on local machine...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(x_train.shape[0], 300, input_length=19607))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=1000,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
